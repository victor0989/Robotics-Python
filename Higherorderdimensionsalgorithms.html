<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c10{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:458pt;border-top-color:#000000;border-bottom-style:solid}.c16{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c18{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Courier New";font-style:italic}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Courier New";font-style:normal}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12.5pt;font-family:"Times New Roman";font-style:italic}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:italic}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c4{padding-top:11pt;padding-bottom:11pt;line-height:1.2;orphans:2;widows:2;text-align:left}.c9{border-spacing:0;border-collapse:collapse;margin-right:auto}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c17{font-size:12pt;font-family:"Times New Roman";font-style:italic;font-weight:400}.c15{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c13{height:0pt}.c8{height:75.2pt}.c7{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c15 doc-content"><p class="c5"><span class="c2">The higher order dimensions algorithm based on cube replication and extrapolation of different sets. The main idea is to compute in Scikit-python the high dimensions to recreate new mathematical and computational scenarios with python. In this example, I show how algorithmic logarithmic regression works to elucidate some important machine learning concepts for Scikit and to propose another level of computational analysis. </span></p><p class="c5"><span class="c2">&nbsp;</span></p><a id="t.3c9232b2d5d9ea2a259f8403ad80b64e9db35916"></a><a id="t.0"></a><table class="c9"><tr class="c13"><td class="c16" colspan="1" rowspan="1"><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 610.00px; height: 236.00px;"><img alt="" src="images/image2.png" style="width: 610.00px; height: 236.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr></table><p class="c5 c7"><span class="c6"></span></p><p class="c5"><span class="c2">We have some functions with logarithms and vectors as exponents.</span></p><p class="c5"><span class="c2">The logarithmic regression works across different higher dimensions that change through a constant t or time and the dimensions replicate each other in a non linear time.The constant time</span></p><p class="c5"><span class="c2">Is not uniform, is chaotic and it depends on regressive algorithms to commute with each other in different cube states or dimensional states. </span></p><p class="c5"><span class="c2">Composition of higher dimensions:</span></p><p class="c5 c7"><span class="c2"></span></p><p class="c5"><span class="c2">Algebras from vector and hyperplane arrangements</span></p><p class="c5"><span class="c2">There are several natural algebraic spaces related to the Tutte polynomial arising in commutative</span></p><p class="c5"><span class="c2">algebra, hyperplane arrangements, box splines, and index theory; we discuss a few. For each</span></p><p class="c5"><span class="c2">hyperplane H in a hyperplane arrangement A in k d let lH be a linear function such that H is given by the equation lH(x) = 0.</span></p><p class="c5 c7"><span class="c2"></span></p><a id="t.290468e6cc737db74f563dabeba8f609f7553a03"></a><a id="t.1"></a><table class="c9"><tr class="c13"><td class="c16" colspan="1" rowspan="1"><p class="c4"><span class="c3">f(x)=1+logx6,logx6(2x+4)&minus;log6P</span></p><p class="c4"><span class="c3">Prop:</span></p><p class="c4"><span class="c3">f(x) 1+logx6(Dimension1&#8203;)=logx6&lowast;(Dimension2&#8203;)</span></p><p class="c4"><span class="c3">VECTORS (variable(exp3)&lt;=== &nbsp; &nbsp;&lt;===variable(exp3))</span></p><p class="c4"><span class="c17">1+logx6(Dimension3) = &nbsp;log</span><img src="images/image1.png"></p></td></tr></table><p class="c5 c7"><span class="c6"></span></p><a id="t.892900344be6a5b61ac673f4116ced66f50b3f18"></a><a id="t.2"></a><table class="c9"><tr class="c8"><td class="c18" colspan="1" rowspan="1"><p class="c4"><span class="c2">A matroid subdivision is a polyhedral subdivision P of a matroid polytope PM where every polytope P &isin; P is itself a matroid polytope. Equivalently, it is a subdivision of PM whose only edges are the edges of PM. In the most important case, M is the uniform matroid Ud,and PM is the hypersimplex &#8710;(d, n).</span></p><p class="c4"><span class="c2">Matroid subdivisions arose in algebraic geometry [HKT06, Kap93, Laf03], in the theory of evaluated matroids [DW92, Mur96], and in tropical geometry [Spe08]. For instance, Lafforgue showed that if a matroid polytope PM has no nontrivial matroid subdivisions, then the matroid M has (up to trivial transformations) only finitely many realizations over a fixed field F. This is one of very few results about realizability of matroids over arbitrary fields.</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 610.00px; height: 129.33px;"><img alt="" src="images/image4.png" style="width: 610.00px; height: 129.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c7"><span class="c3"></span></p><p class="c4"><span class="c2">This formula is straightforward in terms of coboundary polynomials: &chi;M(k) (X, Y ) = &chi;M(X, Y K). For an extensive generalization, see Section 7.9.</span></p><p class="c4"><span class="c2">&bull; [Ard07a, Mph00] Root systems are arguably the most important vector configurations; these highly symmetric arrangements play a fundamental role in many branches of mathematics. For the general definition and properties, see for example [Hum90]; we focus on the four infinite families of classical root systems</span></p><a id="t.9950d7a9261546b9e32b073d9056f0f0a8c43b9e"></a><a id="t.3"></a><table class="c9"><tr class="c13"><td class="c10" colspan="1" rowspan="1"><p class="c1"><span class="c2">An&minus;1 = {ei &minus; ej , : 1 &le; i &lt; j &le; n}</span></p><p class="c1"><span class="c2">Bn = {ei &minus; ej , ei + ej : 1 &le; i &lt; j &le; n} &cup; {ei</span></p><p class="c1"><span class="c2">: 1 &le; i &le; n}</span></p><p class="c1"><span class="c2">Cn = {ei &minus; ej , ei + ej : 1 &le; i &lt; j &le; n} &cup; {2ei</span></p><p class="c1"><span class="c2">: 1 &le; i &le; n}</span></p><p class="c1"><span class="c2">Dn = {ei &minus; ej , ei + ej : 1 &le; i &lt; j &le; </span></p><p class="c1 c7"><span class="c2"></span></p></td></tr></table><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 610.00px; height: 184.00px;"><img alt="" src="images/image3.png" style="width: 610.00px; height: 184.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c7"><span class="c3"></span></p><p class="c4"><span class="c17">Regression equations in 562 scikit-learn</span></p><a id="t.91b03a62de08b2740f3a32b346080574dd3c2db6"></a><a id="t.4"></a><table class="c9"><tr class="c13"><td class="c10" colspan="1" rowspan="1"><p class="c1"><span class="c0">import numpy as np</span></p><p class="c1"><span class="c0">from sklearn.datasets import load_boston</span></p><p class="c1"><span class="c0">from sklearn.ensemble import RandomForestRegressor</span></p><p class="c1"><span class="c0">from sklearn.pipeline import Pipeline</span></p><p class="c1"><span class="c0">from sklearn.preprocessing import Imputer</span></p><p class="c1"><span class="c0">from sklearn.model_selection import cross_val_score</span></p><p class="c1"><span class="c0">rng = np.random.RandomState(0)</span></p><p class="c1"><span class="c0">dataset = load_boston()</span></p><p class="c1"><span class="c0">X_full, y_full = dataset.data, dataset.target</span></p><p class="c1"><span class="c0">n_samples = X_full.shape[0]</span></p><p class="c1"><span class="c0">n_features = X_full.shape[1]</span></p><p class="c1"><span class="c0"># Estimate the score on the entire dataset, with no missing values</span></p><p class="c1"><span class="c0">estimator = RandomForestRegressor(random_state=0, n_estimators=100)</span></p><p class="c1"><span class="c0">score = cross_val_score(estimator, X_full, y_full).mean()</span></p><p class="c1"><span class="c0">print(&quot;Score with the entire dataset = %.2f&quot; % score)</span></p><p class="c1"><span class="c0"># Add missing values in 75% of the lines</span></p><p class="c1"><span class="c0">missing_rate = 0.75</span></p><p class="c1"><span class="c0">n_missing_samples = np.floor(n_samples * missing_rate)</span></p><p class="c1"><span class="c0">missing_samples = np.hstack((np.zeros(n_samples - n_missing_samples,</span></p><p class="c1"><span class="c0">dtype=np.bool),</span></p><p class="c1"><span class="c0">np.ones(n_missing_samples,</span></p><p class="c1"><span class="c0">dtype=np.bool)))</span></p><p class="c1"><span class="c0">rng.shuffle(missing_samples)</span></p><p class="c1"><span class="c0">missing_features = rng.randint(0, n_features, n_missing_samples)</span></p><p class="c1"><span class="c0"># Estimate the score without the lines containing missing values</span></p><p class="c1"><span class="c0">X_filtered = X_full[~missing_samples, :]</span></p><p class="c1"><span class="c0">y_filtered = y_full[~missing_samples]</span></p><p class="c1"><span class="c0">estimator = RandomForestRegressor(random_state=0, n_estimators=100)</span></p><p class="c1"><span class="c0">score = cross_val_score(estimator, X_filtered, y_filtered).mean()</span></p><p class="c1"><span class="c0">print(&quot;Score without the samples containing missing values = %.2f&quot; % score)</span></p><p class="c1"><span class="c0"># Estimate the score after imputation of the missing values</span></p><p class="c1"><span class="c0">X_missing = X_full.copy()</span></p><p class="c1"><span class="c0">X_missing[np.where(missing_samples)[0], missing_features] = 0</span></p><p class="c1"><span class="c0">y_missing = y_full.copy()</span></p><p class="c1"><span class="c0">estimator = Pipeline([(&quot;imputer&quot;, Imputer(missing_values=0,</span></p><p class="c1"><span class="c0">strategy=&quot;mean&quot;,</span></p><p class="c1"><span class="c0">axis=0)),</span></p><p class="c1"><span class="c0">(&quot;forest&quot;, RandomForestRegressor(random_state=0,</span></p><p class="c1"><span class="c0">n_estimators=100))])</span></p><p class="c1"><span class="c0">score = cross_val_score(estimator, X_missing, y_missing).mean()</span></p><p class="c1"><span class="c0">print(&quot;Score after imputation of the missing values = %.2f&quot; % score)</span></p><p class="c1 c7"><span class="c0"></span></p></td></tr></table><p class="c4 c7"><span class="c3"></span></p><p class="c4 c7"><span class="c3"></span></p><p class="c4 c7"><span class="c12"></span></p><p class="c4 c7"><span class="c12"></span></p><p class="c4 c7"><span class="c12"></span></p><p class="c4 c7"><span class="c12"></span></p><p class="c4 c7"><span class="c11"></span></p><p class="c4 c7"><span class="c11"></span></p><p class="c4 c7"><span class="c11"></span></p></td></tr></table><p class="c5 c7"><span class="c6"></span></p></body></html>